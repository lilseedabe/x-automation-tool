"""
ğŸ§  Xè‡ªå‹•åå¿œãƒ„ãƒ¼ãƒ« - AIæŠ•ç¨¿ãƒ»ãƒ¦ãƒ¼ã‚¶ãƒ¼åˆ†æã‚¨ãƒ³ã‚¸ãƒ³
ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ã‚¨ãƒ³ã‚²ãƒ¼ã‚¸ãƒ¡ãƒ³ãƒˆå“è³ªã¨ãƒãƒ†ãƒ³ã‚·ãƒ£ãƒ«ã‚’ AI åˆ†æ
"""

import logging
import re
import random
from datetime import datetime, timezone
from typing import Dict, Any, List, Optional

logger = logging.getLogger(__name__)

class PostAnalyzer:
    """AIæŠ•ç¨¿ãƒ»ãƒ¦ãƒ¼ã‚¶ãƒ¼åˆ†æã‚¯ãƒ©ã‚¹"""
    
    def __init__(self):
        """AIåˆ†æã‚¨ãƒ³ã‚¸ãƒ³åˆæœŸåŒ–"""
        self.spam_keywords = [
            "ç„¡æ–™", "å³é‡‘", "ç°¡å˜", "å‰¯æ¥­", "åœ¨å®…", "æŠ•è³‡", "å„²ã‹ã‚‹", "ç¨¼ã’ã‚‹",
            "é™å®š", "ä»Šã ã‘", "æ€¥ã„ã§", "ãƒ•ã‚©ãƒ­ãƒ", "ç›¸äº’ãƒ•ã‚©ãƒ­ãƒ¼", "RTå¸Œæœ›",
            "æ‹¡æ•£å¸Œæœ›", "ã„ã„ã­è¿”ã—", "spam", "bot", "fake"
        ]
        
        self.quality_keywords = [
            "ã‚ã‚ŠãŒã¨ã†", "ç´ æ™´ã‚‰ã—ã„", "å‹‰å¼·ã«ãªã‚‹", "å‚è€ƒã«ãªã‚‹", "æ„Ÿè¬",
            "å­¦ã³", "æˆé•·", "æŒ‘æˆ¦", "åŠªåŠ›", "ç¶™ç¶š", "ç›®æ¨™", "é”æˆ",
            "æŠ€è¡“", "é–‹ç™º", "ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°", "ãƒ‡ã‚¶ã‚¤ãƒ³", "ãƒãƒ¼ã‚±ãƒ†ã‚£ãƒ³ã‚°"
        ]
        
        logger.info("ğŸ§  AIåˆ†æã‚¨ãƒ³ã‚¸ãƒ³åˆæœŸåŒ–å®Œäº†")
    
    async def analyze_user_engagement_quality(
        self, 
        user_data: Dict[str, Any], 
        recent_tweets: List[Dict[str, Any]], 
        original_tweet: Dict[str, Any]
    ) -> Dict[str, Any]:
        """
        ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ã‚¨ãƒ³ã‚²ãƒ¼ã‚¸ãƒ¡ãƒ³ãƒˆå“è³ªã‚’ AI åˆ†æ
        
        Args:
            user_data: ãƒ¦ãƒ¼ã‚¶ãƒ¼åŸºæœ¬æƒ…å ±
            recent_tweets: ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®æœ€è¿‘ã®ãƒ„ã‚¤ãƒ¼ãƒˆ
            original_tweet: å…ƒã®ãƒ„ã‚¤ãƒ¼ãƒˆï¼ˆåå¿œã•ã‚ŒãŸãƒ„ã‚¤ãƒ¼ãƒˆï¼‰
            
        Returns:
            AIåˆ†æçµæœ
        """
        try:
            logger.debug(f"ğŸ” ãƒ¦ãƒ¼ã‚¶ãƒ¼åˆ†æé–‹å§‹: @{user_data.get('username', 'unknown')}")
            
            # å„ç¨®ã‚¹ã‚³ã‚¢ã‚’è¨ˆç®—
            profile_score = self._analyze_profile_quality(user_data)
            activity_score = self._analyze_activity_quality(recent_tweets)
            engagement_score = self._analyze_engagement_authenticity(user_data, original_tweet)
            content_score = self._analyze_content_quality(recent_tweets)
            
            # ç·åˆã‚¹ã‚³ã‚¢è¨ˆç®—ï¼ˆé‡ã¿ä»˜ã‘å¹³å‡ï¼‰
            weights = {
                "profile": 0.25,
                "activity": 0.20,
                "engagement": 0.30,
                "content": 0.25
            }
            
            final_score = (
                profile_score * weights["profile"] +
                activity_score * weights["activity"] +
                engagement_score * weights["engagement"] +
                content_score * weights["content"]
            )
            
            # ã‚¹ã‚³ã‚¢ã‚’0-1ã®ç¯„å›²ã«æ­£è¦åŒ–
            final_score = max(0, min(1, final_score))
            
            # å“è³ªã‚«ãƒ†ã‚´ãƒªã‚’æ±ºå®š
            quality_category = self._determine_quality_category(final_score)
            
            # ã‚¨ãƒ³ã‚²ãƒ¼ã‚¸ãƒ¡ãƒ³ãƒˆæ¨å¥¨åº¦ã‚’è¨ˆç®—
            engagement_recommendation = self._calculate_engagement_recommendation(
                final_score, user_data, recent_tweets
            )
            
            analysis_result = {
                "engagement_score": round(final_score, 3),
                "quality_category": quality_category,
                "score_breakdown": {
                    "profile_score": round(profile_score, 3),
                    "activity_score": round(activity_score, 3),
                    "engagement_score": round(engagement_score, 3),
                    "content_score": round(content_score, 3)
                },
                "engagement_recommendation": engagement_recommendation,
                "analysis_details": {
                    "follower_ratio": self._calculate_follower_ratio(user_data),
                    "activity_level": self._assess_activity_level(recent_tweets),
                    "content_diversity": self._assess_content_diversity(recent_tweets),
                    "spam_indicators": self._detect_spam_indicators(user_data, recent_tweets)
                },
                "analyzed_at": datetime.now(timezone.utc)
            }
            
            logger.debug(f"âœ… ãƒ¦ãƒ¼ã‚¶ãƒ¼åˆ†æå®Œäº†: @{user_data.get('username')} ã‚¹ã‚³ã‚¢={final_score:.3f}")
            return analysis_result
            
        except Exception as e:
            logger.error(f"âŒ ãƒ¦ãƒ¼ã‚¶ãƒ¼åˆ†æã‚¨ãƒ©ãƒ¼: {str(e)}")
            # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã®ä½ã‚¹ã‚³ã‚¢ã‚’è¿”ã™
            return {
                "engagement_score": 0.1,
                "quality_category": "very_low",
                "score_breakdown": {
                    "profile_score": 0.1,
                    "activity_score": 0.1,
                    "engagement_score": 0.1,
                    "content_score": 0.1
                },
                "engagement_recommendation": "avoid",
                "analysis_details": {"error": str(e)},
                "analyzed_at": datetime.now(timezone.utc)
            }
    
    def _analyze_profile_quality(self, user_data: Dict[str, Any]) -> float:
        """ãƒ—ãƒ­ãƒ•ã‚£ãƒ¼ãƒ«å“è³ªã‚’åˆ†æ"""
        score = 0.5  # ãƒ™ãƒ¼ã‚¹ã‚¹ã‚³ã‚¢
        
        try:
            # ãƒ•ã‚©ãƒ­ãƒ¯ãƒ¼æ•°åˆ†æ
            followers = user_data["public_metrics"]["followers_count"]
            following = user_data["public_metrics"]["following_count"]
            
            # ãƒ•ã‚©ãƒ­ãƒ¯ãƒ¼æ•°ã«ã‚ˆã‚‹åŠ ç‚¹
            if followers > 1000:
                score += 0.2
            elif followers > 100:
                score += 0.1
            elif followers < 10:
                score -= 0.2
            
            # ãƒ•ã‚©ãƒ­ãƒ¼æ¯”ç‡åˆ†æ
            if following > 0:
                ratio = followers / following
                if 0.5 <= ratio <= 2.0:
                    score += 0.1
                elif ratio < 0.1 or ratio > 10:
                    score -= 0.2
            
            # èªè¨¼ãƒãƒƒã‚¸
            if user_data.get("verified"):
                score += 0.2
            
            # ãƒ—ãƒ­ãƒ•ã‚£ãƒ¼ãƒ«è¨˜è¿°
            bio = user_data.get("description", "")
            if bio:
                score += 0.1
                # ã‚¹ãƒ‘ãƒ ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãƒã‚§ãƒƒã‚¯
                if any(keyword in bio.lower() for keyword in self.spam_keywords):
                    score -= 0.3
                # å“è³ªã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãƒã‚§ãƒƒã‚¯
                if any(keyword in bio.lower() for keyword in self.quality_keywords):
                    score += 0.1
            
        except Exception as e:
            logger.warning(f"âš ï¸ ãƒ—ãƒ­ãƒ•ã‚£ãƒ¼ãƒ«åˆ†æã‚¨ãƒ©ãƒ¼: {str(e)}")
        
        return max(0, min(1, score))
    
    def _analyze_activity_quality(self, recent_tweets: List[Dict[str, Any]]) -> float:
        """ã‚¢ã‚¯ãƒ†ã‚£ãƒ“ãƒ†ã‚£å“è³ªã‚’åˆ†æ"""
        score = 0.5  # ãƒ™ãƒ¼ã‚¹ã‚¹ã‚³ã‚¢
        
        try:
            if not recent_tweets:
                return 0.2  # ãƒ„ã‚¤ãƒ¼ãƒˆãŒãªã„å ´åˆã¯ä½ã‚¹ã‚³ã‚¢
            
            # ãƒ„ã‚¤ãƒ¼ãƒˆæ•°ã«ã‚ˆã‚‹è©•ä¾¡
            tweet_count = len(recent_tweets)
            if 2 <= tweet_count <= 10:
                score += 0.2
            elif tweet_count > 15:
                score -= 0.1  # éåº¦ãªæŠ•ç¨¿ã¯æ¸›ç‚¹
            
            # ã‚¨ãƒ³ã‚²ãƒ¼ã‚¸ãƒ¡ãƒ³ãƒˆç‡åˆ†æ
            total_likes = sum(tweet.get("public_metrics", {}).get("like_count", 0) for tweet in recent_tweets)
            total_retweets = sum(tweet.get("public_metrics", {}).get("retweet_count", 0) for tweet in recent_tweets)
            
            avg_engagement = (total_likes + total_retweets) / tweet_count if tweet_count > 0 else 0
            
            if avg_engagement > 50:
                score += 0.3
            elif avg_engagement > 10:
                score += 0.2
            elif avg_engagement > 1:
                score += 0.1
            
        except Exception as e:
            logger.warning(f"âš ï¸ ã‚¢ã‚¯ãƒ†ã‚£ãƒ“ãƒ†ã‚£åˆ†æã‚¨ãƒ©ãƒ¼: {str(e)}")
        
        return max(0, min(1, score))
    
    def _analyze_engagement_authenticity(self, user_data: Dict[str, Any], original_tweet: Dict[str, Any]) -> float:
        """ã‚¨ãƒ³ã‚²ãƒ¼ã‚¸ãƒ¡ãƒ³ãƒˆã®çœŸæ­£æ€§ã‚’åˆ†æ"""
        score = 0.6  # ãƒ™ãƒ¼ã‚¹ã‚¹ã‚³ã‚¢
        
        try:
            # ã‚¨ãƒ³ã‚²ãƒ¼ã‚¸ãƒ¡ãƒ³ãƒˆã‚¿ã‚¤ãƒ—ã«ã‚ˆã‚‹è©•ä¾¡
            engagement_type = user_data.get("engagement_type", "")
            
            if engagement_type == "like":
                score += 0.1  # ã„ã„ã­ã¯ä¸€èˆ¬çš„
            elif engagement_type == "retweet":
                score += 0.2  # ãƒªãƒ„ã‚¤ãƒ¼ãƒˆã¯ã‚ˆã‚Šä¾¡å€¤ãŒé«˜ã„
            elif engagement_type == "reply":
                score += 0.3  # ãƒªãƒ—ãƒ©ã‚¤ã¯æœ€ã‚‚ä¾¡å€¤ãŒé«˜ã„
            
            # ã‚¨ãƒ³ã‚²ãƒ¼ã‚¸ãƒ¡ãƒ³ãƒˆã‚¿ã‚¤ãƒŸãƒ³ã‚°åˆ†æ
            engagement_time = user_data.get("engagement_time")
            if engagement_time:
                # å³åº§ã®åå¿œã¯çœŸæ­£æ€§ãŒé«˜ã„
                score += 0.1
            
            # ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ãƒ•ã‚©ãƒ­ãƒ¯ãƒ¼æ•°ã¨ã‚¨ãƒ³ã‚²ãƒ¼ã‚¸ãƒ¡ãƒ³ãƒˆã®é–¢ä¿‚
            followers = user_data["public_metrics"]["followers_count"]
            if 100 <= followers <= 10000:
                score += 0.1  # ä¸­è¦æ¨¡ãƒ¦ãƒ¼ã‚¶ãƒ¼ã¯ä¾¡å€¤ãŒé«˜ã„
            elif followers > 100000:
                score -= 0.1  # å¤§è¦æ¨¡ã‚¢ã‚«ã‚¦ãƒ³ãƒˆã¯å½±éŸ¿åŠ›ãŒã‚ã‚‹ãŒå€‹äººçš„é–¢ä¿‚ã¯è–„ã„
            
        except Exception as e:
            logger.warning(f"âš ï¸ ã‚¨ãƒ³ã‚²ãƒ¼ã‚¸ãƒ¡ãƒ³ãƒˆçœŸæ­£æ€§åˆ†æã‚¨ãƒ©ãƒ¼: {str(e)}")
        
        return max(0, min(1, score))
    
    def _analyze_content_quality(self, recent_tweets: List[Dict[str, Any]]) -> float:
        """ã‚³ãƒ³ãƒ†ãƒ³ãƒ„å“è³ªã‚’åˆ†æ"""
        score = 0.5  # ãƒ™ãƒ¼ã‚¹ã‚¹ã‚³ã‚¢
        
        try:
            if not recent_tweets:
                return 0.2
            
            quality_count = 0
            spam_count = 0
            
            for tweet in recent_tweets:
                text = tweet.get("text", "").lower()
                
                # å“è³ªã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã®æ¤œå‡º
                if any(keyword in text for keyword in self.quality_keywords):
                    quality_count += 1
                
                # ã‚¹ãƒ‘ãƒ ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã®æ¤œå‡º
                if any(keyword in text for keyword in self.spam_keywords):
                    spam_count += 1
                
                # URLéå¤šãƒã‚§ãƒƒã‚¯
                if text.count("http") > 2:
                    spam_count += 1
                
                # ãƒãƒƒã‚·ãƒ¥ã‚¿ã‚°éå¤šãƒã‚§ãƒƒã‚¯
                if text.count("#") > 5:
                    spam_count += 1
                
                # åŒã˜å†…å®¹ã®ç¹°ã‚Šè¿”ã—ãƒã‚§ãƒƒã‚¯
                # (ç°¡ç•¥åŒ–å®Ÿè£…)
            
            # ã‚¹ã‚³ã‚¢èª¿æ•´
            if quality_count > 0:
                score += min(0.3, quality_count * 0.1)
            
            if spam_count > 0:
                score -= min(0.4, spam_count * 0.1)
            
            # å¤šæ§˜æ€§ãƒœãƒ¼ãƒŠã‚¹
            unique_words = set()
            for tweet in recent_tweets:
                words = tweet.get("text", "").split()
                unique_words.update(words)
            
            if len(unique_words) > 50:
                score += 0.1
            
        except Exception as e:
            logger.warning(f"âš ï¸ ã‚³ãƒ³ãƒ†ãƒ³ãƒ„å“è³ªåˆ†æã‚¨ãƒ©ãƒ¼: {str(e)}")
        
        return max(0, min(1, score))
    
    def _determine_quality_category(self, score: float) -> str:
        """ã‚¹ã‚³ã‚¢ã‹ã‚‰å“è³ªã‚«ãƒ†ã‚´ãƒªã‚’æ±ºå®š"""
        if score >= 0.8:
            return "excellent"
        elif score >= 0.6:
            return "good"
        elif score >= 0.4:
            return "fair"
        elif score >= 0.2:
            return "poor"
        else:
            return "very_poor"
    
    def _calculate_engagement_recommendation(
        self, 
        score: float, 
        user_data: Dict[str, Any], 
        recent_tweets: List[Dict[str, Any]]
    ) -> str:
        """ã‚¨ãƒ³ã‚²ãƒ¼ã‚¸ãƒ¡ãƒ³ãƒˆæ¨å¥¨åº¦ã‚’è¨ˆç®—"""
        if score >= 0.7:
            return "highly_recommended"
        elif score >= 0.5:
            return "recommended"
        elif score >= 0.3:
            return "conditional"
        else:
            return "avoid"
    
    def _calculate_follower_ratio(self, user_data: Dict[str, Any]) -> float:
        """ãƒ•ã‚©ãƒ­ãƒ¯ãƒ¼æ¯”ç‡ã‚’è¨ˆç®—"""
        try:
            followers = user_data["public_metrics"]["followers_count"]
            following = user_data["public_metrics"]["following_count"]
            return followers / following if following > 0 else float('inf')
        except:
            return 0
    
    def _assess_activity_level(self, recent_tweets: List[Dict[str, Any]]) -> str:
        """ã‚¢ã‚¯ãƒ†ã‚£ãƒ“ãƒ†ã‚£ãƒ¬ãƒ™ãƒ«ã‚’è©•ä¾¡"""
        tweet_count = len(recent_tweets)
        if tweet_count >= 10:
            return "very_active"
        elif tweet_count >= 5:
            return "active"
        elif tweet_count >= 2:
            return "moderate"
        elif tweet_count >= 1:
            return "low"
        else:
            return "inactive"
    
    def _assess_content_diversity(self, recent_tweets: List[Dict[str, Any]]) -> str:
        """ã‚³ãƒ³ãƒ†ãƒ³ãƒ„å¤šæ§˜æ€§ã‚’è©•ä¾¡"""
        if not recent_tweets:
            return "none"
        
        # ç°¡ç•¥åŒ–å®Ÿè£…: ç•°ãªã‚‹å˜èªæ•°ã‚’ã‚«ã‚¦ãƒ³ãƒˆ
        all_words = set()
        for tweet in recent_tweets:
            words = tweet.get("text", "").split()
            all_words.update(words)
        
        unique_ratio = len(all_words) / (len(recent_tweets) * 10) if recent_tweets else 0
        
        if unique_ratio >= 0.8:
            return "very_diverse"
        elif unique_ratio >= 0.6:
            return "diverse"
        elif unique_ratio >= 0.4:
            return "moderate"
        elif unique_ratio >= 0.2:
            return "limited"
        else:
            return "repetitive"
    
    def _detect_spam_indicators(self, user_data: Dict[str, Any], recent_tweets: List[Dict[str, Any]]) -> List[str]:
        """ã‚¹ãƒ‘ãƒ æŒ‡æ¨™ã‚’æ¤œå‡º"""
        indicators = []
        
        try:
            # ãƒ—ãƒ­ãƒ•ã‚£ãƒ¼ãƒ«ã‚¹ãƒ‘ãƒ ãƒã‚§ãƒƒã‚¯
            bio = user_data.get("description", "").lower()
            if any(keyword in bio for keyword in self.spam_keywords):
                indicators.append("spam_keywords_in_bio")
            
            # ãƒ•ã‚©ãƒ­ãƒ¼æ¯”ç‡ç•°å¸¸
            followers = user_data["public_metrics"]["followers_count"]
            following = user_data["public_metrics"]["following_count"]
            
            if following > followers * 10 and followers < 100:
                indicators.append("suspicious_follow_ratio")
            
            # ãƒ„ã‚¤ãƒ¼ãƒˆã‚¹ãƒ‘ãƒ ãƒã‚§ãƒƒã‚¯
            for tweet in recent_tweets:
                text = tweet.get("text", "").lower()
                if any(keyword in text for keyword in self.spam_keywords):
                    indicators.append("spam_keywords_in_tweets")
                    break
            
            # URLéå¤š
            url_count = sum(tweet.get("text", "").count("http") for tweet in recent_tweets)
            if url_count > len(recent_tweets) * 2:
                indicators.append("excessive_urls")
            
        except Exception as e:
            logger.warning(f"âš ï¸ ã‚¹ãƒ‘ãƒ æ¤œå‡ºã‚¨ãƒ©ãƒ¼: {str(e)}")
        
        return indicators