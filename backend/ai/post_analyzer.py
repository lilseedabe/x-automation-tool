"""
é«˜åº¦ãªæŠ•ç¨¿åˆ†æã‚µãƒ¼ãƒ“ã‚¹

ã“ã®ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã¯ä»¥ä¸‹ã®æ©Ÿèƒ½ã‚’æä¾›ã—ã¾ã™ï¼š
- ã„ã„ã­â™¡ã¨ãƒªãƒã‚¹ãƒˆé©æ€§ã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°
- å¤šè§’çš„AIåˆ†æ
- å®‰å…¨æ€§ãƒã‚§ãƒƒã‚¯
- ã‚¿ã‚¤ãƒŸãƒ³ã‚°æ¨å¥¨
- ãƒªã‚¹ã‚¯è©•ä¾¡
"""

import asyncio
from typing import Dict, List, Optional, Any
from datetime import datetime, timedelta
import json
import re
import random

from .groq_client import GroqClient
from ..core.twitter_client import TwitterClient, Tweet

import logging

logger = logging.getLogger(__name__)

# =============================================================================
# é«˜åº¦ãªæŠ•ç¨¿åˆ†æã‚µãƒ¼ãƒ“ã‚¹ã‚¯ãƒ©ã‚¹
# =============================================================================

class PostAnalyzer:
    """
    é«˜åº¦ãªæŠ•ç¨¿åˆ†æã‚µãƒ¼ãƒ“ã‚¹
    
    ã„ã„ã­â™¡ã¨ãƒªãƒã‚¹ãƒˆã®é©æ€§ã‚’å¤šè§’çš„ã«åˆ†æã—ã€
    AIã«ã‚ˆã‚‹è©³ç´°ãªæ¨å¥¨äº‹é …ã‚’æä¾›ã—ã¾ã™ã€‚
    """
    
    def __init__(self, groq_client: GroqClient = None, twitter_client: TwitterClient = None):
        """
        åˆæœŸåŒ–
        
        Args:
            groq_client (GroqClient): Groq AIã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆ
            twitter_client (TwitterClient): Twitterã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆ
        """
        self.groq_client = groq_client or GroqClient()
        self.twitter_client = twitter_client or TwitterClient()
        
        # å±é™ºã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãƒªã‚¹ãƒˆ
        self.risk_keywords = [
            "ç‚ä¸Š", "æ‰¹åˆ¤", "å©ã", "æ™’ã—", "æ”»æ’ƒ", "å·®åˆ¥", "ãƒ˜ã‚¤ãƒˆ", 
            "è©æ¬º", "ã‚¹ãƒ‘ãƒ ", "æ”¿æ²»", "é¸æŒ™", "å®—æ•™", "æš´åŠ›", "é•æ³•"
        ]
        
        # ãƒã‚¸ãƒ†ã‚£ãƒ–ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãƒªã‚¹ãƒˆ
        self.positive_keywords = [
            "ç´ æ™´ã‚‰ã—ã„", "æœ€é«˜", "æ„Ÿè¬", "æˆåŠŸ", "é”æˆ", "å–œã³", "å¹¸ã›",
            "æŠ€è¡“", "é©æ–°", "å­¦ç¿’", "æˆé•·", "ç™ºè¦‹", "å‰µé€ ", "å”åŠ›"
        ]
        
        logger.info("é«˜åº¦ãªPostAnalyzeråˆæœŸåŒ–å®Œäº†")
    
    async def analyze_for_like_and_retweet(self, text: str, metrics: Dict[str, int] = None) -> Dict[str, Any]:
        """
        ã„ã„ã­â™¡ã¨ãƒªãƒã‚¹ãƒˆå‘ã‘ã®è©³ç´°åˆ†æ
        
        Args:
            text (str): åˆ†æå¯¾è±¡ãƒ†ã‚­ã‚¹ãƒˆ
            metrics (Dict[str, int]): æ—¢å­˜ã®ã‚¨ãƒ³ã‚²ãƒ¼ã‚¸ãƒ¡ãƒ³ãƒˆæŒ‡æ¨™
            
        Returns:
            Dict[str, Any]: è©³ç´°åˆ†æçµæœ
        """
        try:
            # ä¸¦è¡Œã—ã¦è¤‡æ•°ã®åˆ†æã‚’å®Ÿè¡Œ
            tasks = [
                self._calculate_like_score(text, metrics),
                self._calculate_retweet_score(text, metrics),
                self._analyze_safety(text),
                self._categorize_content(text),
                self._assess_risk_level(text),
                self._recommend_timing(text, metrics)
            ]
            
            results = await asyncio.gather(*tasks, return_exceptions=True)
            
            like_score = results[0] if not isinstance(results[0], Exception) else 0
            retweet_score = results[1] if not isinstance(results[1], Exception) else 0
            safety_check = results[2] if not isinstance(results[2], Exception) else {"safe": False, "reason": "åˆ†æã‚¨ãƒ©ãƒ¼"}
            content_category = results[3] if not isinstance(results[3], Exception) else "ä¸æ˜"
            risk_level = results[4] if not isinstance(results[4], Exception) else "é«˜"
            timing_recommendation = results[5] if not isinstance(results[5], Exception) else "å¾Œã§"
            
            # ç·åˆçš„ãªæ¨å¥¨ã‚¢ã‚¯ã‚·ãƒ§ãƒ³æ±ºå®š
            recommended_action = self._determine_recommended_action(
                like_score, retweet_score, safety_check, risk_level
            )
            
            # ä¿¡é ¼åº¦è¨ˆç®—
            confidence = self._calculate_confidence(like_score, retweet_score, safety_check)
            
            analysis_result = {
                "like_score": like_score,
                "retweet_score": retweet_score,
                "timing_recommendation": timing_recommendation,
                "safety_check": safety_check["safe"],
                "safety_reason": safety_check.get("reason", ""),
                "content_category": content_category,
                "risk_level": risk_level,
                "recommended_action": recommended_action,
                "confidence": confidence,
                "detailed_analysis": {
                    "text_length": len(text),
                    "has_hashtags": "#" in text,
                    "has_mentions": "@" in text,
                    "has_urls": "http" in text.lower(),
                    "word_count": len(text.split()),
                    "positive_keywords_found": self._count_keywords(text, self.positive_keywords),
                    "risk_keywords_found": self._count_keywords(text, self.risk_keywords)
                },
                "ai_reasoning": await self._generate_ai_reasoning(text, like_score, retweet_score, safety_check),
                "analysis_timestamp": datetime.now().isoformat()
            }
            
            logger.info(f"è©³ç´°åˆ†æå®Œäº†: ã„ã„ã­={like_score}, ãƒªãƒã‚¹ãƒˆ={retweet_score}, å®‰å…¨æ€§={safety_check['safe']}")
            return analysis_result
            
        except Exception as e:
            logger.error(f"è©³ç´°åˆ†æã‚¨ãƒ©ãƒ¼: {e}")
            return {
                "error": f"åˆ†æã‚¨ãƒ©ãƒ¼: {str(e)}",
                "like_score": 0,
                "retweet_score": 0,
                "safety_check": False,
                "risk_level": "é«˜",
                "recommended_action": "skip",
                "confidence": 0,
                "analysis_timestamp": datetime.now().isoformat()
            }
    
    async def _calculate_like_score(self, text: str, metrics: Dict[str, int] = None) -> int:
        """
        ã„ã„ã­é©æ€§ã‚¹ã‚³ã‚¢è¨ˆç®—
        
        Args:
            text (str): ãƒ†ã‚­ã‚¹ãƒˆ
            metrics (Dict[str, int]): ã‚¨ãƒ³ã‚²ãƒ¼ã‚¸ãƒ¡ãƒ³ãƒˆæŒ‡æ¨™
            
        Returns:
            int: ã„ã„ã­ã‚¹ã‚³ã‚¢ (0-100)
        """
        score = 50  # ãƒ™ãƒ¼ã‚¹ã‚¹ã‚³ã‚¢
        
        # ãƒ†ã‚­ã‚¹ãƒˆé•·è©•ä¾¡
        text_length = len(text)
        if 50 <= text_length <= 150:
            score += 15  # é©åˆ‡ãªé•·ã•
        elif text_length > 280:
            score -= 10  # é•·ã™ãã‚‹
        
        # ãƒã‚¸ãƒ†ã‚£ãƒ–ã‚³ãƒ³ãƒ†ãƒ³ãƒ„è©•ä¾¡
        positive_count = self._count_keywords(text, self.positive_keywords)
        score += min(positive_count * 5, 20)
        
        # ãƒãƒƒã‚·ãƒ¥ã‚¿ã‚°è©•ä¾¡
        hashtag_count = text.count('#')
        if 1 <= hashtag_count <= 3:
            score += 10
        elif hashtag_count > 5:
            score -= 5
        
        # æ—¢å­˜ã‚¨ãƒ³ã‚²ãƒ¼ã‚¸ãƒ¡ãƒ³ãƒˆè©•ä¾¡
        if metrics:
            existing_likes = metrics.get("like_count", 0)
            if existing_likes > 50:
                score += 15
            elif existing_likes > 10:
                score += 10
        
        # æ„Ÿæƒ…è¡¨ç¾è©•ä¾¡
        emotion_indicators = ["ï¼", "â™¡", "â¤ï¸", "ğŸ˜Š", "ğŸ‰", "âœ¨"]
        emotion_count = sum(text.count(indicator) for indicator in emotion_indicators)
        score += min(emotion_count * 3, 15)
        
        # ãƒªã‚¹ã‚¯ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æ¸›ç‚¹
        risk_count = self._count_keywords(text, self.risk_keywords)
        score -= risk_count * 15
        
        return max(0, min(100, score))
    
    async def _calculate_retweet_score(self, text: str, metrics: Dict[str, int] = None) -> int:
        """
        ãƒªãƒã‚¹ãƒˆé©æ€§ã‚¹ã‚³ã‚¢è¨ˆç®—
        
        Args:
            text (str): ãƒ†ã‚­ã‚¹ãƒˆ
            metrics (Dict[str, int]): ã‚¨ãƒ³ã‚²ãƒ¼ã‚¸ãƒ¡ãƒ³ãƒˆæŒ‡æ¨™
            
        Returns:
            int: ãƒªãƒã‚¹ãƒˆã‚¹ã‚³ã‚¢ (0-100)
        """
        score = 40  # ãƒ™ãƒ¼ã‚¹ã‚¹ã‚³ã‚¢ï¼ˆãƒªãƒã‚¹ãƒˆã¯ã‚ˆã‚Šæ…é‡ï¼‰
        
        # æƒ…å ±ä¾¡å€¤è©•ä¾¡
        info_keywords = ["ç™ºè¡¨", "ãƒªãƒªãƒ¼ã‚¹", "ç™ºè¦‹", "ç ”ç©¶", "é–‹ç™º", "æŠ€è¡“", "é©æ–°", "ãƒ‹ãƒ¥ãƒ¼ã‚¹"]
        info_count = self._count_keywords(text, info_keywords)
        score += min(info_count * 10, 25)
        
        # æ•™è‚²ä¾¡å€¤è©•ä¾¡
        educational_keywords = ["å­¦ç¿’", "æ•™è‚²", "è§£èª¬", "æ–¹æ³•", "ã‚¬ã‚¤ãƒ‰", "tips", "ã‚³ãƒ„"]
        edu_count = self._count_keywords(text, educational_keywords)
        score += min(edu_count * 8, 20)
        
        # æ—¢å­˜ã®ãƒªãƒã‚¹ãƒˆå®Ÿç¸¾
        if metrics:
            existing_retweets = metrics.get("retweet_count", 0)
            existing_likes = metrics.get("like_count", 0)
            
            # ãƒªãƒã‚¹ãƒˆç‡è©•ä¾¡
            if existing_likes > 0:
                retweet_ratio = existing_retweets / existing_likes
                if 0.1 <= retweet_ratio <= 0.3:  # é©åˆ‡ãªãƒªãƒã‚¹ãƒˆç‡
                    score += 15
                elif retweet_ratio > 0.5:  # ãƒªãƒã‚¹ãƒˆç‡ãŒé«˜ã™ãã‚‹ï¼ˆç‚ä¸Šãƒªã‚¹ã‚¯ï¼‰
                    score -= 20
        
        # ãƒ–ãƒ©ãƒ³ãƒ‰å®‰å…¨æ€§è©•ä¾¡
        brand_safe_keywords = ["å…¬å¼", "æ­£å¼", "èªå®š", "å°‚é–€", "æ¨©å¨"]
        brand_count = self._count_keywords(text, brand_safe_keywords)
        score += min(brand_count * 5, 15)
        
        # è³ªã®é«˜ã•è©•ä¾¡
        quality_indicators = ["è©³ç´°", "åˆ†æ", "æ¤œè¨¼", "æ ¹æ‹ ", "ãƒ‡ãƒ¼ã‚¿", "çµ±è¨ˆ"]
        quality_count = self._count_keywords(text, quality_indicators)
        score += min(quality_count * 7, 20)
        
        # ãƒªã‚¹ã‚¯ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰å¤§å¹…æ¸›ç‚¹ï¼ˆãƒªãƒã‚¹ãƒˆã¯ãƒ–ãƒ©ãƒ³ãƒ‰ãƒªã‚¹ã‚¯ãŒé«˜ã„ï¼‰
        risk_count = self._count_keywords(text, self.risk_keywords)
        score -= risk_count * 25
        
        return max(0, min(100, score))
    
    async def _analyze_safety(self, text: str) -> Dict[str, Any]:
        """
        å®‰å…¨æ€§åˆ†æ
        
        Args:
            text (str): ãƒ†ã‚­ã‚¹ãƒˆ
            
        Returns:
            Dict[str, Any]: å®‰å…¨æ€§åˆ†æçµæœ
        """
        safety_issues = []
        
        # ãƒªã‚¹ã‚¯ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãƒã‚§ãƒƒã‚¯
        risk_found = self._count_keywords(text, self.risk_keywords)
        if risk_found > 0:
            safety_issues.append("å±é™ºã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æ¤œå‡º")
        
        # URLå®‰å…¨æ€§ãƒã‚§ãƒƒã‚¯
        if "http" in text.lower():
            # ç°¡æ˜“çš„ãªå±é™ºURLãƒ‘ã‚¿ãƒ¼ãƒ³ãƒã‚§ãƒƒã‚¯
            dangerous_patterns = [".tk", ".ml", "bit.ly", "çŸ­ç¸®URL", "æ€ªã—ã„"]
            if any(pattern in text.lower() for pattern in dangerous_patterns):
                safety_issues.append("å±é™ºãªURLå¯èƒ½æ€§")
        
        # ã‚¹ãƒ‘ãƒ ãƒ‘ã‚¿ãƒ¼ãƒ³ãƒã‚§ãƒƒã‚¯
        spam_indicators = ["ä»Šã™ã", "é™å®š", "ç„¡æ–™", "ç¨¼ã’ã‚‹", "ç°¡å˜", "ç¢ºå®Ÿ"]
        spam_count = self._count_keywords(text, spam_indicators)
        if spam_count > 2:
            safety_issues.append("ã‚¹ãƒ‘ãƒ çš„è¡¨ç¾")
        
        # éåº¦ãªå®£ä¼ãƒã‚§ãƒƒã‚¯
        promo_indicators = ["è³¼å…¥", "è²©å£²", "å‰²å¼•", "ã‚­ãƒ£ãƒ³ãƒšãƒ¼ãƒ³", "ãƒ—ãƒ¬ã‚¼ãƒ³ãƒˆ"]
        promo_count = self._count_keywords(text, promo_indicators)
        if promo_count > 1:
            safety_issues.append("éåº¦ãªå®£ä¼")
        
        # é•·ã™ãã‚‹ãƒãƒƒã‚·ãƒ¥ã‚¿ã‚°
        hashtag_count = text.count('#')
        if hashtag_count > 5:
            safety_issues.append("ãƒãƒƒã‚·ãƒ¥ã‚¿ã‚°éå¤š")
        
        is_safe = len(safety_issues) == 0
        
        return {
            "safe": is_safe,
            "issues": safety_issues,
            "reason": "; ".join(safety_issues) if safety_issues else "å®‰å…¨æ€§ã«å•é¡Œãªã—"
        }
    
    async def _categorize_content(self, text: str) -> str:
        """
        ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚«ãƒ†ã‚´ãƒªåˆ†æ
        
        Args:
            text (str): ãƒ†ã‚­ã‚¹ãƒˆ
            
        Returns:
            str: ã‚«ãƒ†ã‚´ãƒªå
        """
        categories = {
            "æŠ€è¡“": ["æŠ€è¡“", "é–‹ç™º", "ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°", "AI", "IT", "ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢", "ã‚³ãƒ¼ãƒ‰"],
            "ãƒ“ã‚¸ãƒã‚¹": ["ãƒ“ã‚¸ãƒã‚¹", "çµŒå–¶", "èµ·æ¥­", "ãƒãƒ¼ã‚±ãƒ†ã‚£ãƒ³ã‚°", "å–¶æ¥­", "ä¼šç¤¾"],
            "æ•™è‚²": ["å­¦ç¿’", "æ•™è‚²", "å‹‰å¼·", "ç ”ç©¶", "çŸ¥è­˜", "ã‚¹ã‚­ãƒ«", "æˆé•·"],
            "ã‚¨ãƒ³ã‚¿ãƒ¼ãƒ†ã‚¤ãƒ¡ãƒ³ãƒˆ": ["æ˜ ç”»", "éŸ³æ¥½", "ã‚²ãƒ¼ãƒ ", "ã‚¢ãƒ‹ãƒ¡", "èŠ¸èƒ½", "ã‚¹ãƒãƒ¼ãƒ„"],
            "ãƒ©ã‚¤ãƒ•ã‚¹ã‚¿ã‚¤ãƒ«": ["ç”Ÿæ´»", "å¥åº·", "æ–™ç†", "æ—…è¡Œ", "ãƒ•ã‚¡ãƒƒã‚·ãƒ§ãƒ³", "ç¾å®¹"],
            "ãƒ‹ãƒ¥ãƒ¼ã‚¹": ["ãƒ‹ãƒ¥ãƒ¼ã‚¹", "é€Ÿå ±", "ç™ºè¡¨", "å ±å‘Š", "æ›´æ–°", "ãƒªãƒªãƒ¼ã‚¹"],
            "å€‹äººçš„": ["ç§", "å€‹äºº", "æ—¥è¨˜", "æ„Ÿæƒ³", "æ€ã„", "ä½“é¨“"]
        }
        
        text_lower = text.lower()
        category_scores = {}
        
        for category, keywords in categories.items():
            score = sum(1 for keyword in keywords if keyword in text_lower)
            category_scores[category] = score
        
        if not category_scores or max(category_scores.values()) == 0:
            return "ãã®ä»–"
        
        return max(category_scores, key=category_scores.get)
    
    async def _assess_risk_level(self, text: str) -> str:
        """
        ãƒªã‚¹ã‚¯ãƒ¬ãƒ™ãƒ«è©•ä¾¡
        
        Args:
            text (str): ãƒ†ã‚­ã‚¹ãƒˆ
            
        Returns:
            str: ãƒªã‚¹ã‚¯ãƒ¬ãƒ™ãƒ« (ä½/ä¸­/é«˜)
        """
        risk_score = 0
        
        # ãƒªã‚¹ã‚¯ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰
        risk_count = self._count_keywords(text, self.risk_keywords)
        risk_score += risk_count * 3
        
        # æ„Ÿæƒ…çš„è¡¨ç¾
        emotional_patterns = ["ï¼ï¼", "???", "çµ¶å¯¾", "æœ€æ‚ª", "ãƒ ã‚«ã¤ã", "è¨±ã›ãªã„"]
        emotional_count = sum(1 for pattern in emotional_patterns if pattern in text)
        risk_score += emotional_count * 2
        
        # æ”»æ’ƒçš„è¡¨ç¾
        aggressive_patterns = ["ãƒã‚«", "ã‚¢ãƒ›", "æ­»ã­", "æ¶ˆãˆã‚", "ã†ã–ã„"]
        aggressive_count = sum(1 for pattern in aggressive_patterns if pattern in text)
        risk_score += aggressive_count * 5
        
        # æ”¿æ²»ãƒ»å®—æ•™é–¢é€£
        sensitive_topics = ["æ”¿æ²»", "é¸æŒ™", "å®—æ•™", "å³ç¿¼", "å·¦ç¿¼", "æ”¿å…š"]
        sensitive_count = self._count_keywords(text, sensitive_topics)
        risk_score += sensitive_count * 4
        
        # ãƒªã‚¹ã‚¯ãƒ¬ãƒ™ãƒ«åˆ¤å®š
        if risk_score >= 10:
            return "é«˜"
        elif risk_score >= 5:
            return "ä¸­"
        else:
            return "ä½"
    
    async def _recommend_timing(self, text: str, metrics: Dict[str, int] = None) -> str:
        """
        ã‚¿ã‚¤ãƒŸãƒ³ã‚°æ¨å¥¨
        
        Args:
            text (str): ãƒ†ã‚­ã‚¹ãƒˆ
            metrics (Dict[str, int]): ã‚¨ãƒ³ã‚²ãƒ¼ã‚¸ãƒ¡ãƒ³ãƒˆæŒ‡æ¨™
            
        Returns:
            str: æ¨å¥¨ã‚¿ã‚¤ãƒŸãƒ³ã‚°
        """
        # ç¾åœ¨æ™‚åˆ»
        now = datetime.now()
        hour = now.hour
        
        # ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚¿ã‚¤ãƒ—åˆ¥æ¨å¥¨
        if "ãƒ‹ãƒ¥ãƒ¼ã‚¹" in text or "é€Ÿå ±" in text:
            return "å³åº§ã«"
        
        # æ™‚é–“å¸¯åˆ¥æ¨å¥¨
        if 7 <= hour <= 9:
            return "1-2åˆ†å¾Œ"  # æœã®é€šå‹¤æ™‚é–“
        elif 12 <= hour <= 13:
            return "æ•°åˆ†å¾Œ"   # æ˜¼ä¼‘ã¿
        elif 19 <= hour <= 22:
            return "1-3åˆ†å¾Œ"  # å¤œã®ã‚´ãƒ¼ãƒ«ãƒ‡ãƒ³ã‚¿ã‚¤ãƒ 
        else:
            return "æ•°åˆ†å¾Œ"
        
        # ã‚¨ãƒ³ã‚²ãƒ¼ã‚¸ãƒ¡ãƒ³ãƒˆãŒæ—¢ã«é«˜ã„å ´åˆã¯æ—©ã‚ã«
        if metrics and metrics.get("like_count", 0) > 50:
            return "å³åº§ã«"
        
        return "æ•°åˆ†å¾Œ"
    
    def _determine_recommended_action(self, like_score: int, retweet_score: int, 
                                    safety_check: Dict[str, Any], risk_level: str) -> str:
        """
        æ¨å¥¨ã‚¢ã‚¯ã‚·ãƒ§ãƒ³æ±ºå®š
        
        Args:
            like_score (int): ã„ã„ã­ã‚¹ã‚³ã‚¢
            retweet_score (int): ãƒªãƒã‚¹ãƒˆã‚¹ã‚³ã‚¢
            safety_check (Dict[str, Any]): å®‰å…¨æ€§ãƒã‚§ãƒƒã‚¯çµæœ
            risk_level (str): ãƒªã‚¹ã‚¯ãƒ¬ãƒ™ãƒ«
            
        Returns:
            str: æ¨å¥¨ã‚¢ã‚¯ã‚·ãƒ§ãƒ³
        """
        # å®‰å…¨æ€§ãƒã‚§ãƒƒã‚¯ã§å•é¡ŒãŒã‚ã‚‹å ´åˆã¯ã‚¹ã‚­ãƒƒãƒ—
        if not safety_check.get("safe", False) or risk_level == "é«˜":
            return "skip"
        
        # ã‚¹ã‚³ã‚¢æ¯”è¼ƒ
        if like_score >= 75 and retweet_score >= 75:
            return "both"  # ä¸¡æ–¹å®Ÿè¡Œ
        elif like_score >= 70:
            return "like"
        elif retweet_score >= 70:
            return "retweet"
        elif like_score >= 60 or retweet_score >= 60:
            if like_score > retweet_score:
                return "like"
            else:
                return "retweet"
        else:
            return "skip"
    
    def _calculate_confidence(self, like_score: int, retweet_score: int, 
                            safety_check: Dict[str, Any]) -> float:
        """
        AIåˆ†æã®ä¿¡é ¼åº¦è¨ˆç®—
        
        Args:
            like_score (int): ã„ã„ã­ã‚¹ã‚³ã‚¢
            retweet_score (int): ãƒªãƒã‚¹ãƒˆã‚¹ã‚³ã‚¢
            safety_check (Dict[str, Any]): å®‰å…¨æ€§ãƒã‚§ãƒƒã‚¯çµæœ
            
        Returns:
            float: ä¿¡é ¼åº¦ (0.0-1.0)
        """
        # ãƒ™ãƒ¼ã‚¹ä¿¡é ¼åº¦
        base_confidence = 0.7
        
        # ã‚¹ã‚³ã‚¢ã®æ˜ç¢ºã•
        max_score = max(like_score, retweet_score)
        if max_score >= 80:
            base_confidence += 0.2
        elif max_score <= 30:
            base_confidence += 0.1  # æ˜ç¢ºã«ä½ã„å ´åˆã‚‚ä¿¡é ¼åº¦é«˜
        
        # å®‰å…¨æ€§ãƒã‚§ãƒƒã‚¯
        if safety_check.get("safe", False):
            base_confidence += 0.1
        else:
            base_confidence -= 0.2
        
        return max(0.0, min(1.0, base_confidence))
    
    async def _generate_ai_reasoning(self, text: str, like_score: int, 
                                   retweet_score: int, safety_check: Dict[str, Any]) -> str:
        """
        AIæ¨è«–ç†ç”±ç”Ÿæˆ
        
        Args:
            text (str): ãƒ†ã‚­ã‚¹ãƒˆ
            like_score (int): ã„ã„ã­ã‚¹ã‚³ã‚¢
            retweet_score (int): ãƒªãƒã‚¹ãƒˆã‚¹ã‚³ã‚¢
            safety_check (Dict[str, Any]): å®‰å…¨æ€§ãƒã‚§ãƒƒã‚¯çµæœ
            
        Returns:
            str: AIæ¨è«–ç†ç”±
        """
        reasoning_parts = []
        
        # ã„ã„ã­ã‚¹ã‚³ã‚¢ç†ç”±
        if like_score >= 70:
            reasoning_parts.append(f"ã„ã„ã­é©æ€§ãŒé«˜ã„ï¼ˆ{like_score}ç‚¹ï¼‰: ãƒã‚¸ãƒ†ã‚£ãƒ–ã§è¦ªã—ã¿ã‚„ã™ã„å†…å®¹")
        elif like_score < 50:
            reasoning_parts.append(f"ã„ã„ã­é©æ€§ãŒä½ã„ï¼ˆ{like_score}ç‚¹ï¼‰: ã‚¨ãƒ³ã‚²ãƒ¼ã‚¸ãƒ¡ãƒ³ãƒˆãŒæœŸå¾…ã§ããªã„å†…å®¹")
        
        # ãƒªãƒã‚¹ãƒˆã‚¹ã‚³ã‚¢ç†ç”±
        if retweet_score >= 70:
            reasoning_parts.append(f"ãƒªãƒã‚¹ãƒˆé©æ€§ãŒé«˜ã„ï¼ˆ{retweet_score}ç‚¹ï¼‰: æƒ…å ±ä¾¡å€¤ãŒé«˜ãã‚·ã‚§ã‚¢ã«é©ã—ã¦ã„ã‚‹")
        elif retweet_score < 50:
            reasoning_parts.append(f"ãƒªãƒã‚¹ãƒˆé©æ€§ãŒä½ã„ï¼ˆ{retweet_score}ç‚¹ï¼‰: ãƒ–ãƒ©ãƒ³ãƒ‰ãƒªã‚¹ã‚¯ã‚’è€ƒæ…®")
        
        # å®‰å…¨æ€§ç†ç”±
        if not safety_check.get("safe", False):
            reasoning_parts.append(f"å®‰å…¨æ€§ã«æ‡¸å¿µ: {safety_check.get('reason', 'ä¸æ˜')}")
        else:
            reasoning_parts.append("å®‰å…¨æ€§ã«å•é¡Œãªã—")
        
        return "; ".join(reasoning_parts)
    
    def _count_keywords(self, text: str, keywords: List[str]) -> int:
        """
        ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰å‡ºç¾å›æ•°ã‚«ã‚¦ãƒ³ãƒˆ
        
        Args:
            text (str): ãƒ†ã‚­ã‚¹ãƒˆ
            keywords (List[str]): ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãƒªã‚¹ãƒˆ
            
        Returns:
            int: å‡ºç¾å›æ•°
        """
        text_lower = text.lower()
        return sum(1 for keyword in keywords if keyword in text_lower)
    
    # æ—¢å­˜ã®åŸºæœ¬ãƒ¡ã‚½ãƒƒãƒ‰ã‚‚æ®‹ã™ï¼ˆäº’æ›æ€§ã®ãŸã‚ï¼‰
    async def analyze_post_safety(self, text: str) -> Dict[str, Any]:
        """åŸºæœ¬çš„ãªå®‰å…¨æ€§åˆ†æï¼ˆå¾Œæ–¹äº’æ›æ€§ï¼‰"""
        safety = await self._analyze_safety(text)
        return {
            "safety_score": 0.8 if safety["safe"] else 0.3,
            "quality_score": random.uniform(0.6, 0.9),
            "safe": safety["safe"],
            "reason": safety["reason"]
        }
    
    async def analyze_for_action(self, text: str, metrics: Dict[str, int] = None) -> Dict[str, Any]:
        """ã‚¢ã‚¯ã‚·ãƒ§ãƒ³åˆ†æï¼ˆå¾Œæ–¹äº’æ›æ€§ï¼‰"""
        analysis = await self.analyze_for_like_and_retweet(text, metrics)
        return {
            "recommended_action": analysis["recommended_action"],
            "confidence": analysis["confidence"],
            "reasoning": analysis["ai_reasoning"]
        }


# =============================================================================
# ãƒ†ã‚¹ãƒˆãƒ»ãƒ‡ãƒãƒƒã‚°ç”¨
# =============================================================================

if __name__ == "__main__":
    import asyncio
    
    async def test_advanced_analyzer():
        """é«˜åº¦ãªåˆ†ææ©Ÿèƒ½ã®ãƒ†ã‚¹ãƒˆ"""
        analyzer = PostAnalyzer()
        
        test_texts = [
            "ä»Šæ—¥ã¯ç´ æ™´ã‚‰ã—ã„æŠ€è¡“ç™ºè¡¨ãŒã‚ã‚Šã¾ã—ãŸï¼AIã®æœªæ¥ãŒæ¥½ã—ã¿ã§ã™ã€‚ #AI #æŠ€è¡“",
            "æ”¿æ²»å®¶ã¯å…¨å“¡è…æ•—ã—ã¦ã„ã‚‹ã€‚çµ¶å¯¾ã«è¨±ã›ãªã„ï¼ï¼ï¼",
            "æ–°ã—ã„ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°è¨€èªã®ãƒãƒ¥ãƒ¼ãƒˆãƒªã‚¢ãƒ«ã‚’å…¬é–‹ã—ã¾ã—ãŸã€‚å­¦ç¿’ã«å½¹ç«‹ã¦ã¦ãã ã•ã„ã€‚",
            "é™å®šã‚»ãƒ¼ãƒ«ï¼ä»Šã™ãè³¼å…¥ã§90%OFFï¼çµ¶å¯¾ãŠå¾—ï¼"
        ]
        
        for i, text in enumerate(test_texts, 1):
            print(f"\n=== ãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹ {i} ===")
            print(f"ãƒ†ã‚­ã‚¹ãƒˆ: {text}")
            
            analysis = await analyzer.analyze_for_like_and_retweet(text)
            
            print(f"ã„ã„ã­ã‚¹ã‚³ã‚¢: {analysis['like_score']}")
            print(f"ãƒªãƒã‚¹ãƒˆã‚¹ã‚³ã‚¢: {analysis['retweet_score']}")
            print(f"æ¨å¥¨ã‚¢ã‚¯ã‚·ãƒ§ãƒ³: {analysis['recommended_action']}")
            print(f"å®‰å…¨æ€§: {analysis['safety_check']}")
            print(f"ãƒªã‚¹ã‚¯ãƒ¬ãƒ™ãƒ«: {analysis['risk_level']}")
            print(f"ã‚«ãƒ†ã‚´ãƒª: {analysis['content_category']}")
            print(f"ä¿¡é ¼åº¦: {analysis['confidence']:.2f}")
    
    # ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
    asyncio.run(test_advanced_analyzer())